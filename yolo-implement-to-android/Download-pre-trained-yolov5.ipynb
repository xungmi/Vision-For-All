{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df8e043",
   "metadata": {},
   "source": [
    "# Tải pretrained yolo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8321b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
      "100 14.1M  100 14.1M    0     0  5012k      0  0:00:02  0:00:02 --:--:-- 8701k\n"
     ]
    }
   ],
   "source": [
    "# !curl -LO https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52eee2c",
   "metadata": {},
   "source": [
    "# Cài đặt công cụ cần thiết"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ad7f45",
   "metadata": {},
   "source": [
    "## Cài đặt môi trường với anaconda\n",
    "Tạo môi trường trước, rồi sử dụng các lệnh sau\n",
    "-\tList env:\n",
    "Conda env list\n",
    "-\tCheck version tương thích giữa tensorflow và python và cuda và cudnn trên window\n",
    "https://www.tensorflow.org/install/source_windows#gpu\n",
    " \n",
    "-\tInstall tensorflow tương thích với gpu:\n",
    "conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0\n",
    "pip install \"tensorflow<2.11\"\n",
    "pip install \"numpy<2.0\"\n",
    "-\tCheck tf và active gpu thành công:\n",
    "python -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a56f4a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed4c4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.6.0-cp39-cp39-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.21.0-cp39-cp39-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from torch) (4.13.2)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting numpy (from torchvision)\n",
      "  Using cached numpy-2.0.2-cp39-cp39-win_amd64.whl.metadata (59 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Using cached pillow-11.2.1-cp39-cp39-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp39-cp39-win_amd64.whl.metadata (4.1 kB)\n",
      "Using cached torch-2.6.0-cp39-cp39-win_amd64.whl (204.1 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached torchvision-0.21.0-cp39-cp39-win_amd64.whl (1.6 MB)\n",
      "Using cached pillow-11.2.1-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Using cached numpy-2.0.2-cp39-cp39-win_amd64.whl (15.9 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp39-cp39-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, pillow, numpy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.3.2 jinja2-3.1.6 mpmath-1.3.0 networkx-3.2.1 numpy-2.0.2 pillow-11.2.1 sympy-1.13.1 torch-2.6.0 torchvision-0.21.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a68f99fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: onnxruntime in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (1.19.2)\n",
      "Requirement already satisfied: tf2onnx in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (1.16.1)\n",
      "Requirement already satisfied: onnx-simplifier in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (0.4.36)\n",
      "Requirement already satisfied: numpy>=1.20 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from onnx) (1.26.4)\n",
      "Collecting protobuf>=3.20.2 (from onnx)\n",
      "  Using cached protobuf-6.30.2-cp39-cp39-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: coloredlogs in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from onnxruntime) (25.2.10)\n",
      "Requirement already satisfied: packaging in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from onnxruntime) (25.0)\n",
      "Requirement already satisfied: sympy in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from onnxruntime) (1.13.1)\n",
      "Requirement already satisfied: requests in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from tf2onnx) (2.32.3)\n",
      "Requirement already satisfied: six in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from tf2onnx) (1.17.0)\n",
      "  Using cached protobuf-3.20.3-cp39-cp39-win_amd64.whl.metadata (699 bytes)\n",
      "Requirement already satisfied: rich in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from onnx-simplifier) (14.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from requests->tf2onnx) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from requests->tf2onnx) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from requests->tf2onnx) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from requests->tf2onnx) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from rich->onnx-simplifier) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from rich->onnx-simplifier) (2.19.1)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from rich->onnx-simplifier) (4.13.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime) (3.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->onnx-simplifier) (0.1.2)\n",
      "Using cached protobuf-3.20.3-cp39-cp39-win_amd64.whl (904 kB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "Successfully installed protobuf-3.20.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'F:\\Anaconda\\envs\\TFONNX\\Lib\\site-packages\\google\\~rotobuf'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorboard 2.10.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "tensorflow 2.10.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# Cài ONNX + tf2onnx\n",
    "!pip install onnx onnxruntime tf2onnx onnx-simplifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f49d4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8668f831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Tue_Jun_13_19:42:34_Pacific_Daylight_Time_2023\n",
      "Cuda compilation tools, release 12.2, V12.2.91\n",
      "Build cuda_12.2.r12.2/compiler.32965470_0\n"
     ]
    }
   ],
   "source": [
    "# kiểm tra version cuda\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f389cb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.1\n",
      "Num GPUs Available: 1\n",
      "CUDA version (compile time): 64_112\n",
      "cuDNN version (compile time): 64_8\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Kiểm tra phiên bản TensorFlow\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Kiểm tra GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available:\", len(gpus))\n",
    "\n",
    "# In thông tin CUDA/cuDNN từ môi trường biên dịch\n",
    "print(\"CUDA version (compile time):\", tf.sysconfig.get_build_info().get(\"cuda_version\", \"Unknown\"))\n",
    "print(\"cuDNN version (compile time):\", tf.sysconfig.get_build_info().get(\"cudnn_version\", \"Unknown\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f503cd",
   "metadata": {},
   "source": [
    "# Convert .pt sang ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a97d86a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1610431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"yolov5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "158c2a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Vision-For-All\\\\yolo-implement-to-android\\\\yolov5'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12db996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chạy terminal các lệnh sau để cài thư viện\n",
    "#conda install pandas\n",
    "#conda install -c conda-forge opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b0fcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport: \u001b[0mdata=D:\\Vision-For-All\\yolo-implement-to-android\\yolov5\\data\\coco128.yaml, weights=['yolov5s.pt'], imgsz=[640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, per_tensor=False, dynamic=False, cache=, simplify=False, mlmodel=False, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['onnx']\n",
      "YOLOv5  v7.0-416-gfe1d4d99 Python-3.9.21 torch-2.6.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from yolov5s.pt with output shape (1, 25200, 85) (14.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.8s, saved as yolov5s.onnx (28.0 MB)\n",
      "\n",
      "Export complete (1.2s)\n",
      "Results saved to \u001b[1mD:\\Vision-For-All\\yolo-implement-to-android\\yolov5\u001b[0m\n",
      "Detect:          python detect.py --weights yolov5s.onnx \n",
      "Validate:        python val.py --weights yolov5s.onnx \n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5s.onnx')  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "# --weights: đường dẫn tới file .pt\n",
    "# --include onnx: chỉ định convert sang định dạng ONNX\n",
    "# --img 640: kích thước input (có thể là 320, 416, 640,... tùy bạn)\n",
    "# --opset 12: nên dùng opset >= 11 để tương thích tốt hơn\n",
    "!python export.py --weights yolov5s.pt --include onnx --img 640 --opset 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c16c2b",
   "metadata": {},
   "source": [
    "#####  Kiểm tra ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58f49994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model is valid ✅\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "onnx_model = onnx.load(\"yolov5s.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"ONNX model is valid ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfab271e",
   "metadata": {},
   "source": [
    "# ONNX → TensorFlow SavedModel\n",
    "- Yêu cầu trước khi bắt đầu\n",
    "    - File .onnx (ví dụ yolov5s.onnx)\n",
    "    - Python ≥ 3.7, TensorFlow, tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5096f952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original input: images\n"
     ]
    }
   ],
   "source": [
    "## Fix input của mô hình từ 1 3 640 640 sang 1 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9be383",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nếu chưa đủ thư viện\n",
    "#pip install onnx-tf onnx\n",
    "#pip install tensorflow-probability==0.18.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4d7085",
   "metadata": {},
   "source": [
    "#### Kiểm tra ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4defcd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "2025-04-21 11:24:24,289 - onnx-tf - INFO - Start converting onnx pb to tf saved model\n",
      "2025-04-21 11:24:24.372880: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-21 11:24:24.881095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3697 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\Scripts\\onnx-tf.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\onnx_tf\\cli.py\", line 20, in main\n",
      "    return onnx_tf.converter.main(args[1:])\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\onnx_tf\\converter.py\", line 21, in main\n",
      "    convert(**{k: v for k, v in vars(args).items() if v is not None})\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\onnx_tf\\converter.py\", line 147, in convert\n",
      "    tf_rep.export_graph(outdir)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\onnx_tf\\backend_rep.py\", line 143, in export_graph\n",
      "    signatures=self.tf_module.__call__.get_concrete_function(\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 1239, in get_concrete_function\n",
      "    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 1219, in _get_concrete_function_garbage_collected\n",
      "    self._initialize(args, kwargs, add_initializers_to=initializers)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 785, in _initialize\n",
      "    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2523, in _get_concrete_function_internal_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2760, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2670, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1247, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 677, in wrapped_fn\n",
      "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3317, in bound_method_wrapper\n",
      "    return wrapped_fn(*args, **kwargs)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1233, in autograph_handler\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1222, in autograph_handler\n",
      "    return autograph.converted_call(\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 439, in converted_call\n",
      "    result = converted_f(*effective_args, **kwargs)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Temp\\__autograph_generated_fileecmbqw9o.py\", line 30, in tf____call__\n",
      "    ag__.for_stmt(ag__.ld(self).graph_def.node, None, loop_body, get_state, set_state, (), {'iterate_names': 'node'})\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 463, in for_stmt\n",
      "    _py_for_stmt(iter_, extra_test, body, None, None)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 512, in _py_for_stmt\n",
      "    body(target)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 478, in protected_body\n",
      "    original_body(protected_iter)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Temp\\__autograph_generated_fileecmbqw9o.py\", line 23, in loop_body\n",
      "    output_ops = ag__.converted_call(ag__.ld(self).backend._onnx_node_to_tensorflow_op, (ag__.ld(onnx_node), ag__.ld(tensor_dict), ag__.ld(self).handlers), dict(opset=ag__.ld(self).opset, strict=ag__.ld(self).strict), fscope)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 439, in converted_call\n",
      "    result = converted_f(*effective_args, **kwargs)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Temp\\__autograph_generated_filet6wkcdzh.py\", line 62, in tf___onnx_node_to_tensorflow_op\n",
      "    ag__.if_stmt(ag__.ld(handlers), if_body_1, else_body_1, get_state_1, set_state_1, ('do_return', 'retval_'), 2)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 1363, in if_stmt\n",
      "    _py_if_stmt(cond, body, orelse)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 1416, in _py_if_stmt\n",
      "    return body() if cond else orelse()\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Temp\\__autograph_generated_filet6wkcdzh.py\", line 56, in if_body_1\n",
      "    ag__.if_stmt(ag__.ld(handler), if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 1363, in if_stmt\n",
      "    _py_if_stmt(cond, body, orelse)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 1416, in _py_if_stmt\n",
      "    return body() if cond else orelse()\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Temp\\__autograph_generated_filet6wkcdzh.py\", line 48, in if_body\n",
      "    retval_ = ag__.converted_call(ag__.ld(handler).handle, (ag__.ld(node),), dict(tensor_dict=ag__.ld(tensor_dict), strict=ag__.ld(strict)), fscope)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 439, in converted_call\n",
      "    result = converted_f(*effective_args, **kwargs)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Temp\\__autograph_generated_filej3vx9tlq.py\", line 41, in tf__handle\n",
      "    ag__.if_stmt(ag__.ld(ver_handle), if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 1363, in if_stmt\n",
      "    _py_if_stmt(cond, body, orelse)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 1416, in _py_if_stmt\n",
      "    return body() if cond else orelse()\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Temp\\__autograph_generated_filej3vx9tlq.py\", line 33, in if_body\n",
      "    retval_ = ag__.converted_call(ag__.ld(ver_handle), (ag__.ld(node),), dict(**ag__.ld(kwargs)), fscope)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 439, in converted_call\n",
      "    result = converted_f(*effective_args, **kwargs)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Temp\\__autograph_generated_filerrvc726o.py\", line 12, in tf__version\n",
      "    retval_ = ag__.converted_call(ag__.ld(cls).conv, (ag__.ld(node), ag__.ld(kwargs)['tensor_dict']), None, fscope)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 441, in converted_call\n",
      "    result = converted_f(*effective_args)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Temp\\__autograph_generated_filezrc6w3l5.py\", line 605, in tf__conv\n",
      "    ag__.if_stmt(ag__.ld(transpose), if_body_31, else_body_31, get_state_32, set_state_32, ('convolved', 'x', 'strides'), 2)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 1363, in if_stmt\n",
      "    _py_if_stmt(cond, body, orelse)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 1416, in _py_if_stmt\n",
      "    return body() if cond else orelse()\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Temp\\__autograph_generated_filezrc6w3l5.py\", line 590, in else_body_31\n",
      "    ag__.if_stmt(ag__.ld(depthwise) is True, if_body_30, else_body_30, get_state_31, set_state_31, ('convolved', 'strides'), 1)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 1363, in if_stmt\n",
      "    _py_if_stmt(cond, body, orelse)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\", line 1416, in _py_if_stmt\n",
      "    return body() if cond else orelse()\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Temp\\__autograph_generated_filezrc6w3l5.py\", line 588, in else_body_30\n",
      "    convolved = [ag__.converted_call(ag__.ld(tf).nn.convolution, (ag__.ld(x), ag__.ld(weight)), dict(padding=ag__.ld(pad_mode), strides=ag__.ld(strides), dilations=ag__.ld(dilations), data_format=ag__.ld(compute_format)), fscope) for (x, weight) in ag__.converted_call(ag__.ld(zip), (ag__.ld(xs), ag__.ld(weight_groups)), None, fscope)]\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Temp\\__autograph_generated_filezrc6w3l5.py\", line 588, in <listcomp>\n",
      "    convolved = [ag__.converted_call(ag__.ld(tf).nn.convolution, (ag__.ld(x), ag__.ld(weight)), dict(padding=ag__.ld(pad_mode), strides=ag__.ld(strides), dilations=ag__.ld(dilations), data_format=ag__.ld(compute_format)), fscope) for (x, weight) in ag__.converted_call(ag__.ld(zip), (ag__.ld(xs), ag__.ld(weight_groups)), None, fscope)]\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 377, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 458, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1969, in _create_c_op\n",
      "    raise ValueError(e.message)\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\onnx_tf\\backend_tf_module.py\", line 99, in __call__  *\n",
      "        output_ops = self.backend._onnx_node_to_tensorflow_op(onnx_node,\n",
      "    File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\onnx_tf\\backend.py\", line 347, in _onnx_node_to_tensorflow_op  *\n",
      "        return handler.handle(node, tensor_dict=tensor_dict, strict=strict)\n",
      "    File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\onnx_tf\\handlers\\handler.py\", line 59, in handle  *\n",
      "        return ver_handle(node, **kwargs)\n",
      "    File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\onnx_tf\\handlers\\backend\\conv.py\", line 15, in version_11  *\n",
      "        return cls.conv(node, kwargs[\"tensor_dict\"])\n",
      "    File \"F:\\Anaconda\\envs\\TFONNX\\lib\\site-packages\\onnx_tf\\handlers\\backend\\conv_mixin.py\", line 279, in conv  *\n",
      "        convolved = [\n",
      "\n",
      "    ValueError: Depth of input (640) is not a multiple of input depth of filter (3) for '{{node convolution}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true](transpose_2, split)' with input shapes: [1,7,644,640], [6,6,3,32].\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Convert ONNX → TensorFlow SavedModel\n",
    "!onnx-tf convert -i yolov5_nhwc.onnx -o yolov5_saved_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff26fdae",
   "metadata": {},
   "source": [
    "# SavedModel → TFLite\n",
    "- Yêu cầu:\n",
    "    - TensorFlow đã cài (pip install tensorflow)\n",
    "    - Đã có thư mục SavedModel (saved_model.pb, variables/...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f2794b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Vision-For-All\\\\yolo-implement-to-android'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487e6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load SavedModel\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"yolov5_saved_model\")\n",
    "\n",
    "# (Tùy chọn) Tối ưu hóa cho mobile\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# converter.experimental_new_converter = True\n",
    "# converter.allow_custom_ops = True\n",
    "# converter._experimental_lower_tensor_list_ops = False\n",
    "\n",
    "# # Đặt shape mong muốn (ví dụ 640x640x3)\n",
    "# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "\n",
    "# (Tùy chọn) Hỗ trợ float16 để giảm size nếu device hỗ trợ\n",
    "# converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "# Convert\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Lưu ra file\n",
    "with open(\"yolov5.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d62899a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [{'name': 'serving_default_images:0', 'index': 0, 'shape': array([  1,   3, 640, 640]), 'shape_signature': array([  1,   3, 640, 640]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Output: [{'name': 'PartitionedCall:0', 'index': 527, 'shape': array([    1, 25200,    85]), 'shape_signature': array([    1, 25200,    85]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "## Kiểm tra lại mô hình TFLite\n",
    "interpreter = tf.lite.Interpreter(model_path=\"yolov5.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"Input:\", input_details)\n",
    "print(\"Output:\", output_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09d62f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: [  1   3 640 640]\n",
      "Input dtype: <class 'numpy.float32'>\n",
      "Output shape: [array([    1, 25200,    85])]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=\"yolov5.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"Input shape:\", input_details[0]['shape'])   # <== Quan trọng\n",
    "print(\"Input dtype:\", input_details[0]['dtype'])\n",
    "\n",
    "print(\"Output shape:\", [out['shape'] for out in output_details])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88665285",
   "metadata": {},
   "source": [
    "# Tích hợp vào ứng dụng Android để chạy nhận diện đối tượng"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFONNX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
