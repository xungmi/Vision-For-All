{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df8e043",
   "metadata": {},
   "source": [
    "# Tải pretrained yolo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8321b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
      "100 14.1M  100 14.1M    0     0  5012k      0  0:00:02  0:00:02 --:--:-- 8701k\n"
     ]
    }
   ],
   "source": [
    "# !curl -LO https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52eee2c",
   "metadata": {},
   "source": [
    "# Cài đặt công cụ cần thiết"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ad7f45",
   "metadata": {},
   "source": [
    "## Cài đặt môi trường với anaconda\n",
    "Tạo môi trường trước, rồi sử dụng các lệnh sau\n",
    "-\tList env:\n",
    "Conda env list\n",
    "-\tCheck version tương thích giữa tensorflow và python và cuda và cudnn trên window\n",
    "https://www.tensorflow.org/install/source_windows#gpu\n",
    " \n",
    "-\tInstall tensorflow tương thích với gpu:\n",
    "conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0\n",
    "pip install \"tensorflow<2.11\"\n",
    "pip install \"numpy<2.0\"\n",
    "-\tCheck tf và active gpu thành công:\n",
    "python -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a56f4a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed4c4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.6.0-cp39-cp39-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.21.0-cp39-cp39-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from torch) (4.13.2)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting numpy (from torchvision)\n",
      "  Using cached numpy-2.0.2-cp39-cp39-win_amd64.whl.metadata (59 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Using cached pillow-11.2.1-cp39-cp39-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp39-cp39-win_amd64.whl.metadata (4.1 kB)\n",
      "Using cached torch-2.6.0-cp39-cp39-win_amd64.whl (204.1 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached torchvision-0.21.0-cp39-cp39-win_amd64.whl (1.6 MB)\n",
      "Using cached pillow-11.2.1-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Using cached numpy-2.0.2-cp39-cp39-win_amd64.whl (15.9 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp39-cp39-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, pillow, numpy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.3.2 jinja2-3.1.6 mpmath-1.3.0 networkx-3.2.1 numpy-2.0.2 pillow-11.2.1 sympy-1.13.1 torch-2.6.0 torchvision-0.21.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a68f99fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: onnxruntime in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (1.19.2)\n",
      "Requirement already satisfied: tf2onnx in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (1.16.1)\n",
      "Requirement already satisfied: onnx-simplifier in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (0.4.36)\n",
      "Requirement already satisfied: numpy>=1.20 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from onnx) (1.26.4)\n",
      "Collecting protobuf>=3.20.2 (from onnx)\n",
      "  Using cached protobuf-6.30.2-cp39-cp39-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: coloredlogs in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from onnxruntime) (25.2.10)\n",
      "Requirement already satisfied: packaging in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from onnxruntime) (25.0)\n",
      "Requirement already satisfied: sympy in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from onnxruntime) (1.13.1)\n",
      "Requirement already satisfied: requests in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from tf2onnx) (2.32.3)\n",
      "Requirement already satisfied: six in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from tf2onnx) (1.17.0)\n",
      "  Using cached protobuf-3.20.3-cp39-cp39-win_amd64.whl.metadata (699 bytes)\n",
      "Requirement already satisfied: rich in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from onnx-simplifier) (14.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from requests->tf2onnx) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from requests->tf2onnx) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from requests->tf2onnx) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from requests->tf2onnx) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from rich->onnx-simplifier) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from rich->onnx-simplifier) (2.19.1)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from rich->onnx-simplifier) (4.13.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime) (3.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in f:\\anaconda\\envs\\tfonnx\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->onnx-simplifier) (0.1.2)\n",
      "Using cached protobuf-3.20.3-cp39-cp39-win_amd64.whl (904 kB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "Successfully installed protobuf-3.20.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'F:\\Anaconda\\envs\\TFONNX\\Lib\\site-packages\\google\\~rotobuf'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorboard 2.10.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "tensorflow 2.10.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# Cài ONNX + tf2onnx\n",
    "!pip install onnx onnxruntime tf2onnx onnx-simplifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f49d4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8668f831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Tue_Jun_13_19:42:34_Pacific_Daylight_Time_2023\n",
      "Cuda compilation tools, release 12.2, V12.2.91\n",
      "Build cuda_12.2.r12.2/compiler.32965470_0\n"
     ]
    }
   ],
   "source": [
    "# kiểm tra version cuda\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f389cb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.1\n",
      "Num GPUs Available: 1\n",
      "CUDA version (compile time): 64_112\n",
      "cuDNN version (compile time): 64_8\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Kiểm tra phiên bản TensorFlow\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Kiểm tra GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available:\", len(gpus))\n",
    "\n",
    "# In thông tin CUDA/cuDNN từ môi trường biên dịch\n",
    "print(\"CUDA version (compile time):\", tf.sysconfig.get_build_info().get(\"cuda_version\", \"Unknown\"))\n",
    "print(\"cuDNN version (compile time):\", tf.sysconfig.get_build_info().get(\"cudnn_version\", \"Unknown\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f503cd",
   "metadata": {},
   "source": [
    "# Convert .pt sang ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a97d86a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1610431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"yolov5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "158c2a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Vision-For-All\\\\yolo-implement-to-android\\\\yolov5'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12db996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chạy terminal các lệnh sau để cài thư viện\n",
    "#conda install pandas\n",
    "#conda install -c conda-forge opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b0fcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport: \u001b[0mdata=D:\\Vision-For-All\\yolo-implement-to-android\\yolov5\\data\\coco128.yaml, weights=['yolov5s.pt'], imgsz=[640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, per_tensor=False, dynamic=False, cache=, simplify=False, mlmodel=False, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['onnx']\n",
      "YOLOv5  v7.0-416-gfe1d4d99 Python-3.9.21 torch-2.6.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from yolov5s.pt with output shape (1, 25200, 85) (14.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.8s, saved as yolov5s.onnx (28.0 MB)\n",
      "\n",
      "Export complete (1.2s)\n",
      "Results saved to \u001b[1mD:\\Vision-For-All\\yolo-implement-to-android\\yolov5\u001b[0m\n",
      "Detect:          python detect.py --weights yolov5s.onnx \n",
      "Validate:        python val.py --weights yolov5s.onnx \n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5s.onnx')  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "# --weights: đường dẫn tới file .pt\n",
    "# --include onnx: chỉ định convert sang định dạng ONNX\n",
    "# --img 640: kích thước input (có thể là 320, 416, 640,... tùy bạn)\n",
    "# --opset 12: nên dùng opset >= 11 để tương thích tốt hơn\n",
    "!python export.py --weights yolov5s.pt --include onnx --img 640 --opset 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c16c2b",
   "metadata": {},
   "source": [
    "#####  Kiểm tra ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58f49994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model is valid ✅\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "onnx_model = onnx.load(\"yolov5s.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"ONNX model is valid ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfab271e",
   "metadata": {},
   "source": [
    "# ONNX → TensorFlow SavedModel\n",
    "- Yêu cầu trước khi bắt đầu\n",
    "    - File .onnx (ví dụ yolov5s.onnx)\n",
    "    - Python ≥ 3.7, TensorFlow, tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5096f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix input của mô hình từ 1 3 640 640 sang 1 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec9be383",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nếu chưa đủ thư viện\n",
    "#pip install onnx-tf onnx\n",
    "#pip install tensorflow-probability==0.18.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4d7085",
   "metadata": {},
   "source": [
    "#### Kiểm tra ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4defcd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert ONNX → TensorFlow SavedModel\n",
    "# onnx-tf convert -i yolov5s.onnx -o yolov5s_saved_model_bchw\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717e284e",
   "metadata": {},
   "source": [
    "## Tạo và Chạy Script Python để Wrap và Chuyển đổi sang TFLite (BHWC) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8baaa65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python .\\zconvert_onnx_to_bhwc_tflite.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e636ce",
   "metadata": {},
   "source": [
    "### Thêm metadata vào output của file zconvert_onnx_to_bhwc_tflite.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d1ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cài thư viện hỗ trợ\n",
    "# pip install tflite-support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3e5075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff26fdae",
   "metadata": {},
   "source": [
    "# SavedModel → TFLite\n",
    "- Yêu cầu:\n",
    "    - TensorFlow đã cài (pip install tensorflow)\n",
    "    - Đã có thư mục SavedModel (saved_model.pb, variables/...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487e6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # Load SavedModel\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model(\"yolov5_saved_model\")\n",
    "\n",
    "# # (Tùy chọn) Tối ưu hóa cho mobile\n",
    "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# # converter.experimental_new_converter = True\n",
    "# # converter.allow_custom_ops = True\n",
    "# # converter._experimental_lower_tensor_list_ops = False\n",
    "\n",
    "# # # Đặt shape mong muốn (ví dụ 640x640x3)\n",
    "# # converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "\n",
    "# # (Tùy chọn) Hỗ trợ float16 để giảm size nếu device hỗ trợ\n",
    "# # converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "# # Convert\n",
    "# tflite_model = converter.convert()\n",
    "\n",
    "# # Lưu ra file\n",
    "# with open(\"yolov5.tflite\", \"wb\") as f:\n",
    "#     f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d62899a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [{'name': 'serving_default_input_image_bhwc:0', 'index': 0, 'shape': array([  1, 640, 640,   3]), 'shape_signature': array([  1, 640, 640,   3]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Output: [{'name': 'PartitionedCall:0', 'index': 528, 'shape': array([    1, 25200,    85]), 'shape_signature': array([    1, 25200,    85]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "## Kiểm tra lại mô hình TFLite\n",
    "interpreter = tf.lite.Interpreter(model_path=\"yolov5s_bhwc.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"Input:\", input_details)\n",
    "print(\"Output:\", output_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09d62f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: [  1 640 640   3]\n",
      "Input dtype: <class 'numpy.float32'>\n",
      "Output shape: [array([    1, 25200,    85])]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=\"yolov5s_bhwc.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"Input shape:\", input_details[0]['shape'])   # <== Quan trọng\n",
    "print(\"Input dtype:\", input_details[0]['dtype'])\n",
    "\n",
    "print(\"Output shape:\", [out['shape'] for out in output_details])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88665285",
   "metadata": {},
   "source": [
    "##### Tích hợp vào ứng dụng Android để chạy nhận diện đối tượng"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfpy39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
